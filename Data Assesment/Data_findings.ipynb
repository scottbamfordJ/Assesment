{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [5., 0., 4., ..., 0., 0., 1.],\n",
       "        [2., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "a = sio.mmread('BBC_Data\\\\bbc.mtx')\n",
    "a.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terms = Rows \n",
    "# Docs = Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Terms = open('BBC_Data\\\\bbc.terms', \"r\")\n",
    "data = Terms.read()\n",
    "terms_into_list = data.split(\"\\n\")\n",
    "terms_into_list = terms_into_list[:-1]\n",
    "\n",
    "\n",
    "docs = open('BBC_Data\\\\bbc.docs', \"r\")\n",
    "data = docs.read()\n",
    "docs_into_list = data.split(\"\\n\")\n",
    "\n",
    "test = a.todense()\n",
    "df = pd.DataFrame(test)\n",
    "df['terms'] = terms_into_list\n",
    "df.columns = docs_into_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "Testing_OutPut = []\n",
    "for values in classes:    \n",
    "    filter_col = [col for col in df if col.startswith(values)]\n",
    "    new_dataframe = df[filter_col]\n",
    "\n",
    "    Results = []\n",
    "    for x in range(len(filter_col)):\n",
    "        test = new_dataframe.iloc[:,x]\n",
    "        test = pd.DataFrame(test)\n",
    "        test['terms'] = terms_into_list\n",
    "        test.columns = ['Values', 'Terms']\n",
    "        test_ordered = test.loc[(test[['Values']] != 0).all(axis=1)]\n",
    "\n",
    "        list_of_top_values = test_ordered['Terms']\n",
    "        output = ' '.join(list_of_top_values)\n",
    "        Results.append(output)\n",
    "\n",
    "    Test = {}\n",
    "    for y in Results:\n",
    "        split = y.split()\n",
    "        for strings in split:\n",
    "            if strings in Test:\n",
    "                for key,value in Test.items():\n",
    "                    if key == strings:\n",
    "                        Test[key] = value + 1\n",
    "\n",
    "\n",
    "            else:\n",
    "                x = 1\n",
    "                Test[strings] = x\n",
    "    Testing_OutPut.append((Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_topics (Testing_OutPut,chosen_class , classes):\n",
    "    output = classes.index(chosen_class)\n",
    "    Specific_Class_topics = Testing_OutPut[output]\n",
    "    sorted_output = sorted(Specific_Class_topics.items(), key = lambda kv: kv[1], reverse=True)\n",
    "    dictionary_sorted_output = dict(sorted_output)\n",
    "    return dictionary_sorted_output, sorted_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "\n",
    "business_dict, business_list = getting_topics(Testing_OutPut, 'business', classes)\n",
    "entertainment_dict, entertainment_list = getting_topics(Testing_OutPut, 'entertainment', classes)\n",
    "politics_dict, politics_list = getting_topics(Testing_OutPut, 'politics', classes)\n",
    "sport_dict, sport_list = getting_topics(Testing_OutPut, 'sport', classes)\n",
    "tech_dict, tech_list = getting_topics(Testing_OutPut, 'tech', classes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('peopl', 288),\n",
       " ('on', 260),\n",
       " ('year', 232),\n",
       " ('get', 212),\n",
       " ('wai', 205),\n",
       " ('technolog', 204),\n",
       " ('work', 190),\n",
       " ('time', 187),\n",
       " ('compani', 183),\n",
       " ('user', 182),\n",
       " ('firm', 177),\n",
       " ('servic', 167),\n",
       " ('comput', 165),\n",
       " ('number', 158),\n",
       " ('websit', 157),\n",
       " ('want', 157),\n",
       " ('million', 154),\n",
       " ('world', 152),\n",
       " ('go', 150),\n",
       " ('help', 148),\n",
       " ('take', 148),\n",
       " ('just', 148),\n",
       " ('first', 146),\n",
       " ('need', 145),\n",
       " ('digit', 145),\n",
       " ('develop', 140),\n",
       " ('two', 137),\n",
       " ('offer', 137),\n",
       " ('includ', 136),\n",
       " ('month', 135),\n",
       " ('uk', 135),\n",
       " ('onlin', 134),\n",
       " ('look', 134),\n",
       " ('net', 132),\n",
       " ('market', 132),\n",
       " ('see', 131),\n",
       " ('show', 130),\n",
       " ('000', 130),\n",
       " ('call', 130),\n",
       " ('softwar', 128),\n",
       " ('sai', 128),\n",
       " ('system', 128),\n",
       " ('set', 125),\n",
       " ('research', 125),\n",
       " ('current', 124),\n",
       " ('new', 123),\n",
       " ('game', 123),\n",
       " ('internet', 122),\n",
       " ('player', 120),\n",
       " ('mean', 119)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_list[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic #1 : Using the BBC dataset \n",
    "\n",
    "##### Question 1: For each of the five categories: what are the most common topics among articles?\n",
    "\n",
    "###### For Buisnesses the most common topic was current years financal reports. looking at growth reports in specific sectors as well as looking at the return on investments. \n",
    "\n",
    "###### For Entertainment the Most common topics are looking at award shows and who place where in speccific music or genres. \n",
    "\n",
    "###### For politics, the main topic is about the governing body specifically looking at the different factions within the political sphere. They also seem to use the BBC as a refrence for their debates and topics on politics\n",
    "\n",
    "###### For sports, the main topics are wins vs loses, who has won where and why. As well as identifying areas in which a win could be effected such as injuries or propsects of a new player or replacement. \n",
    "\n",
    "###### For tech, it seems that the major focus of the tech is the interaction between \"People\" and the relationship with the techonoogies that were produced. As well as looking at the different groups of tech firms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "terms_into_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_to_look_for = ['uk', 'britian', 'british', 'japan', 'argentina', \n",
    "    'australia','australian' 'Brazil', 'Canada', 'China', 'France', 'Germany', 'India', 'Indonesia', \n",
    "    'Italy', 'Japan', 'rop', 'korea', 'Mexico', 'Russia', 'Saudi Arabia', 'Saudi', 'South Africa', 'Turkey', \n",
    "    'us', 'america', 'eu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['british', 'britain', 'briton', 'brit', 'britpop', 'britnei', 'britishborn']\n",
      "['japan', 'japanes']\n",
      "['argentina', 'argentin']\n",
      "['australian', 'australia']\n",
      "['brazil', 'brazilian']\n",
      "['canadian', 'canada', 'canadabas']\n",
      "['franc', 'franchis', 'francesco', 'francisco', 'francesca', 'franci', 'franciscobas', 'francai']\n",
      "['french', 'frenchman']\n",
      "['german', 'germani']\n",
      "['indic', 'india', 'indian', 'indirectli', 'individu', 'indict', 'indirect', 'indigen', 'indi', 'indiana', 'indign', 'indispens']\n",
      "['indonesian', 'indonesia']\n",
      "['italian', 'itali']\n",
      "['korea', 'korean']\n",
      "['mexico', 'mexican']\n",
      "['saudi']\n",
      "['africa', 'african', 'africanamerican']\n",
      "['turkei', 'turkish', 'turk']\n",
      "['america', 'american']\n",
      "['usa', 'usada', 'usabl', 'usag']\n",
      "['europ', 'european', 'europewid']\n",
      "['unit', 'union', 'univers', 'uniqu', 'unifi', 'unilev', 'unidentifi', 'uniform', 'uniti', 'unintent', 'unicef', 'unison']\n"
     ]
    }
   ],
   "source": [
    "britian_terms = print( list(filter(lambda x: x.lower().startswith(\"brit\"), terms_into_list)) )\n",
    "japan = print( list(filter(lambda x: x.lower().startswith(\"japa\"), terms_into_list)) )\n",
    "argentina = print( list(filter(lambda x: x.lower().startswith(\"argent\"), terms_into_list)) )\n",
    "australia = print( list(filter(lambda x: x.lower().startswith(\"austral\"), terms_into_list)) )\n",
    "brazil = print( list(filter(lambda x: x.lower().startswith(\"braz\"), terms_into_list)) )\n",
    "canada = print( list(filter(lambda x: x.lower().startswith(\"canad\"), terms_into_list)) )\n",
    "france = print( list(filter(lambda x: x.lower().startswith(\"franc\"), terms_into_list)) )\n",
    "french = print(list(filter(lambda x: x.lower().startswith(\"frenc\"), terms_into_list)) )\n",
    "germany = print(list(filter(lambda x: x.lower().startswith(\"german\"), terms_into_list)) )\n",
    "india = print(list(filter(lambda x: x.lower().startswith(\"indi\"), terms_into_list)) )\n",
    "indonesian = print(list(filter(lambda x: x.lower().startswith(\"indon\"), terms_into_list)) )\n",
    "italy = print(list(filter(lambda x: x.lower().startswith(\"ital\"), terms_into_list)) )\n",
    "korea = print(list(filter(lambda x: x.lower().startswith(\"kore\"), terms_into_list)) )\n",
    "mexico = print(list(filter(lambda x: x.lower().startswith(\"mexi\"), terms_into_list)) )\n",
    "Arabia = print(list(filter(lambda x: x.lower().startswith(\"saud\"), terms_into_list)) )\n",
    "South_African = print(list(filter(lambda x: x.lower().startswith(\"afric\"), terms_into_list)) )\n",
    "turkey = print(list(filter(lambda x: x.lower().startswith(\"turk\"), terms_into_list)) )\n",
    "america = print(list(filter(lambda x: x.lower().startswith(\"ameri\"), terms_into_list)) )\n",
    "us =print(list(filter(lambda x: x.lower().startswith(\"usa\"), terms_into_list)) )\n",
    "EU = print(list(filter(lambda x: x.lower().startswith(\"europ\"), terms_into_list)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8bba0a6b37625271514de0e4c6540b36ac0830cda9ed49ec9a8e7cacf89568c5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('DataScience_Match_Desktop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
