{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [5., 0., 4., ..., 0., 0., 1.],\n",
       "        [2., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "\n",
    "def getting_topics (Testing_OutPut,chosen_class , classes):\n",
    "    output = classes.index(chosen_class)\n",
    "    Specific_Class_topics = Testing_OutPut[output]\n",
    "    sorted_output = sorted(Specific_Class_topics.items(), key = lambda kv: kv[1], reverse=True)\n",
    "    dictionary_sorted_output = dict(sorted_output)\n",
    "    return dictionary_sorted_output, sorted_output\n",
    "\n",
    "\n",
    "\n",
    "a = sio.mmread('BBC_Data\\\\bbc.mtx')\n",
    "Terms = open('BBC_Data\\\\bbc.terms', \"r\")\n",
    "data = Terms.read()\n",
    "terms_into_list = data.split(\"\\n\")\n",
    "terms_into_list = terms_into_list[:-1]\n",
    "\n",
    "\n",
    "docs = open('BBC_Data\\\\bbc.docs', \"r\")\n",
    "data = docs.read()\n",
    "docs_into_list = data.split(\"\\n\")\n",
    "\n",
    "test = a.todense()\n",
    "df = pd.DataFrame(test)\n",
    "df['terms'] = terms_into_list\n",
    "df.columns = docs_into_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "britian = list(filter(lambda x: x.lower().startswith(\"brit\"), terms_into_list)) \n",
    "japan = list(filter(lambda x: x.lower().startswith(\"japa\"), terms_into_list)) \n",
    "argentina = list(filter(lambda x: x.lower().startswith(\"argent\"), terms_into_list)) \n",
    "australia = list(filter(lambda x: x.lower().startswith(\"austral\"), terms_into_list)) \n",
    "brazil = list(filter(lambda x: x.lower().startswith(\"braz\"), terms_into_list)) \n",
    "canada = list(filter(lambda x: x.lower().startswith(\"canad\"), terms_into_list)) \n",
    "#france = print( list(filter(lambda x: x.lower().startswith(\"franc\"), terms_into_list)) )\n",
    "french = list(filter(lambda x: x.lower().startswith(\"frenc\"), terms_into_list)) \n",
    "germany = list(filter(lambda x: x.lower().startswith(\"german\"), terms_into_list)) \n",
    "india = list(filter(lambda x: x.lower().startswith(\"indi\"), terms_into_list))[:3] \n",
    "indonesian = list(filter(lambda x: x.lower().startswith(\"indon\"), terms_into_list)) \n",
    "italy = list(filter(lambda x: x.lower().startswith(\"ital\"), terms_into_list)) \n",
    "korea = list(filter(lambda x: x.lower().startswith(\"kore\"), terms_into_list)) \n",
    "mexico = list(filter(lambda x: x.lower().startswith(\"mexi\"), terms_into_list)) \n",
    "Arabia = list(filter(lambda x: x.lower().startswith(\"saud\"), terms_into_list)) \n",
    "South_African = list(filter(lambda x: x.lower().startswith(\"afric\"), terms_into_list))[:2] \n",
    "turkey = list(filter(lambda x: x.lower().startswith(\"turk\"), terms_into_list)) \n",
    "america = list(filter(lambda x: x.lower().startswith(\"ameri\"), terms_into_list)) \n",
    "us =list(filter(lambda x: x.lower().startswith(\"usa\"), terms_into_list)) \n",
    "EU = list(filter(lambda x: x.lower().startswith(\"europ\"), terms_into_list))[:2] \n",
    "french.append('franc')\n",
    "group_of_terms = [britian, japan, argentina, australia, brazil, canada, french, germany,\n",
    "    india, indonesian, italy, korea, mexico, Arabia, South_African, america, us, EU]\n",
    "britian_count = 0\n",
    "japan_count = 0\n",
    "argentina_count = 0\n",
    "australia_count = 0 \n",
    "brazil_count = 0\n",
    "canada_count = 0\n",
    "french_count = 0\n",
    "germany_count = 0\n",
    "india_count = 0\n",
    "indonesian_count = 0\n",
    "italy_count = 0\n",
    "korea_count = 0\n",
    "mexico_count = 0\n",
    "Arabia_count = 0\n",
    "South_African_count = 0\n",
    "america_count = 0\n",
    "us_count = 0\n",
    "EU_count = 0\n",
    "\n",
    "Counters_Country = [britian_count,japan_count,argentina_count,australia_count,brazil_count,canada_count,french_count,\n",
    "    germany_count,india_count,indonesian_count,italy_count,korea_count,mexico_count,Arabia_count,South_African_count,america_count,us_count,EU_count]\n",
    "    \n",
    "terms_to_look_for = []\n",
    "for values in group_of_terms:\n",
    "    terms_to_look_for.extend(values)\n",
    "\n",
    "\n",
    "print (terms_to_look_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "Testing_OutPut = []\n",
    "for values in classes:    \n",
    "    filter_col = [col for col in df if col.startswith(values)]\n",
    "    new_dataframe = df[filter_col]\n",
    "\n",
    "    Results = []\n",
    "    for x in range(len(filter_col)):\n",
    "        test = new_dataframe.iloc[:,x]\n",
    "        test = pd.DataFrame(test)\n",
    "        test['terms'] = terms_into_list\n",
    "        test.columns = ['Values', 'Terms']\n",
    "        test_ordered = test.loc[(test[['Values']] != 0).all(axis=1)]\n",
    "\n",
    "        list_of_top_values = test_ordered['Terms']\n",
    "        output = ' '.join(list_of_top_values)\n",
    "        Results.append(output)\n",
    "\n",
    "    Test = {}\n",
    "    for y in Results:\n",
    "        split = y.split()\n",
    "        for strings in split:\n",
    "            if strings in Test:\n",
    "                for key,value in Test.items():\n",
    "                    if key == strings:\n",
    "                        Test[key] = value + 1\n",
    "\n",
    "\n",
    "            else:\n",
    "                x = 1\n",
    "                Test[strings] = x\n",
    "    Testing_OutPut.append((Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "\n",
    "business_dict, business_list = getting_topics(Testing_OutPut, 'business', classes)\n",
    "entertainment_dict, entertainment_list = getting_topics(Testing_OutPut, 'entertainment', classes)\n",
    "politics_dict, politics_list = getting_topics(Testing_OutPut, 'politics', classes)\n",
    "sport_dict, sport_list = getting_topics(Testing_OutPut, 'sport', classes)\n",
    "tech_dict, tech_list = getting_topics(Testing_OutPut, 'tech', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is looked at each list and look at the top results to get the general topic of said results. \n",
    "\n",
    "###### Example Code of Process is Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year', 363),\n",
       " ('compani', 267),\n",
       " ('market', 250),\n",
       " ('firm', 244),\n",
       " ('month', 207),\n",
       " ('expect', 199),\n",
       " ('analyst', 184),\n",
       " ('two', 174),\n",
       " ('on', 173),\n",
       " ('chief', 173),\n",
       " ('2004', 172),\n",
       " ('growth', 170),\n",
       " ('govern', 169),\n",
       " ('share', 167),\n",
       " ('time', 162),\n",
       " ('busi', 162),\n",
       " ('report', 162),\n",
       " ('price', 159),\n",
       " ('countri', 156),\n",
       " ('continu', 154),\n",
       " ('sale', 153),\n",
       " ('world', 153),\n",
       " ('rise', 150),\n",
       " ('bank', 149),\n",
       " ('economi', 148),\n",
       " ('econom', 144),\n",
       " ('increas', 142),\n",
       " ('group', 138),\n",
       " ('product', 137),\n",
       " ('000', 136),\n",
       " ('trade', 134),\n",
       " ('recent', 134),\n",
       " ('ad', 133),\n",
       " ('back', 132),\n",
       " ('financi', 131),\n",
       " ('execut', 131),\n",
       " ('plan', 128),\n",
       " ('state', 127),\n",
       " ('sai', 126),\n",
       " ('cost', 125),\n",
       " ('three', 124),\n",
       " ('2005', 124),\n",
       " ('first', 124),\n",
       " ('2003', 119),\n",
       " ('rate', 119),\n",
       " ('demand', 119),\n",
       " ('includ', 119),\n",
       " ('against', 118),\n",
       " ('invest', 118),\n",
       " ('industri', 118)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_list[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business number of references to countries 356\n",
      "356\n",
      "entertainment number of references to countries 237\n",
      "593\n",
      "politics number of references to countries 262\n",
      "855\n",
      "sport number of references to countries 338\n",
      "1193\n",
      "tech number of references to countries 232\n",
      "1425\n"
     ]
    }
   ],
   "source": [
    "classes = ['business', 'entertainment', 'politics', 'sport', 'tech']\n",
    "Testing_OutPut = []\n",
    "Total = 0\n",
    "for values in classes:    \n",
    "    filter_col = [col for col in df if col.startswith(values)]\n",
    "    new_dataframe = df[filter_col]\n",
    "\n",
    "    Results = []\n",
    "    for x in range(len(filter_col)):\n",
    "        test = new_dataframe.iloc[:,x]\n",
    "        test = pd.DataFrame(test)\n",
    "        test['terms'] = terms_into_list\n",
    "        test.columns = ['Values', 'Terms']\n",
    "        test_ordered = test.loc[(test[['Values']] != 0).all(axis=1)]\n",
    "\n",
    "        list_of_top_values = test_ordered['Terms']\n",
    "        output = ' '.join(list_of_top_values)\n",
    "        Results.append(output)\n",
    "\n",
    "    Counter = 0 \n",
    "    for y in Results:\n",
    "        split = y.split()\n",
    "        for strings in split:\n",
    "            if strings in terms_to_look_for:\n",
    "                Counter += 1\n",
    "                break\n",
    "            else: \n",
    "                continue\n",
    "    Total += Counter\n",
    "\n",
    "    for y in Results:\n",
    "        split = y.split()\n",
    "        for strings in split:\n",
    "            # for countries in group_of_terms:\n",
    "            testing_value = 0\n",
    "            while testing_value >= (len(Counters_Country) - 1):\n",
    "                if strings in group_of_terms[testing_value]:\n",
    "                    Counters_Country[testing_value] += 1\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "    for y in Results:\n",
    "        split = y.split()\n",
    "        if any(z in max(split, terms_to_look_for, key=len) for z in min(terms_to_look_for, split, key=len)) == True:\n",
    "            testing_value = 0\n",
    "            while testing_value <= (len(Counters_Country) - 1):\n",
    "                if any(t in max(split, group_of_terms[testing_value], key=len) for t in min(group_of_terms[testing_value], split, key=len)) == True:\n",
    "                    Counters_Country[testing_value] += 1\n",
    "                    break\n",
    "                else: \n",
    "                    testing_value +=1 \n",
    "                        \n",
    "    print(values, 'number of references to countries' , Counter)\n",
    "    print(Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "britian count 1582\n",
      "japan count 411\n",
      "argentina_count 93\n",
      "australia_count 302\n",
      "brazil_count 87\n",
      "canada_count 81\n",
      "french_count 494\n",
      "germany_count 287\n",
      "india_count 408\n",
      "indonesian_count 10\n",
      "italy_count 136\n",
      "korea_count 45\n",
      "mexico_count 24\n",
      "Arabia_count 30\n",
      "South_African_count 121\n",
      "america_count 427\n",
      "us_count 29\n",
      "EU_count 420\n",
      "total counter 4987\n"
     ]
    }
   ],
   "source": [
    "Countries_Counters_Print_Out = ['britian count','japan count','argentina_count',\n",
    "    'australia_count','brazil_count', 'canada_count','french_count','germany_count','india_count', \n",
    "    'indonesian_count', 'italy_count','korea_count','mexico_count','Arabia_count','South_African_count','america_count',\n",
    "    'us_count','EU_count',]\n",
    "\n",
    "totals_test = 0 \n",
    "print_out_counter = 0 \n",
    "for values in Counters_Country:\n",
    "    totals_test += values \n",
    "    print(Countries_Counters_Print_Out[print_out_counter], values)\n",
    "    print_out_counter+=1\n",
    "print('total counter', totals_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_table_country = pd.DataFrame([Countries_Counters_Print_Out, Counters_Country]).T\n",
    "bbc_table_country.columns = ['Countries Counter', 'Number of Articles']\n",
    "#print(bbc_table_country.to_markdown())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sio.mmread('BBC_Sports_Data\\\\bbcsport.mtx')\n",
    "Terms = open('BBC_Sports_Data\\\\bbcsport.terms', \"r\")\n",
    "data = Terms.read()\n",
    "terms_into_list = data.split(\"\\n\")\n",
    "terms_into_list = terms_into_list[:-1]\n",
    "\n",
    "\n",
    "docs = open('BBC_Sports_Data\\\\bbcsport.docs', \"r\")\n",
    "data = docs.read()\n",
    "docs_into_list = data.split(\"\\n\")\n",
    "\n",
    "test = a.todense()\n",
    "df = pd.DataFrame(test)\n",
    "df['terms'] = terms_into_list\n",
    "df.columns = docs_into_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "britian = list(filter(lambda x: x.lower().startswith(\"brit\"), terms_into_list)) \n",
    "japan = list(filter(lambda x: x.lower().startswith(\"japa\"), terms_into_list)) \n",
    "argentina = list(filter(lambda x: x.lower().startswith(\"argent\"), terms_into_list)) \n",
    "australia = list(filter(lambda x: x.lower().startswith(\"austral\"), terms_into_list)) \n",
    "brazil = list(filter(lambda x: x.lower().startswith(\"braz\"), terms_into_list)) \n",
    "canada = list(filter(lambda x: x.lower().startswith(\"canad\"), terms_into_list)) \n",
    "#france = print( list(filter(lambda x: x.lower().startswith(\"franc\"), terms_into_list)) )\n",
    "french = list(filter(lambda x: x.lower().startswith(\"frenc\"), terms_into_list)) \n",
    "germany = list(filter(lambda x: x.lower().startswith(\"german\"), terms_into_list)) \n",
    "india = list(filter(lambda x: x.lower().startswith(\"indi\"), terms_into_list))[:3] \n",
    "indonesian = list(filter(lambda x: x.lower().startswith(\"indon\"), terms_into_list)) \n",
    "italy = list(filter(lambda x: x.lower().startswith(\"ital\"), terms_into_list)) \n",
    "korea = list(filter(lambda x: x.lower().startswith(\"kore\"), terms_into_list)) \n",
    "mexico = list(filter(lambda x: x.lower().startswith(\"mexi\"), terms_into_list)) \n",
    "Arabia = list(filter(lambda x: x.lower().startswith(\"saud\"), terms_into_list)) \n",
    "South_African = list(filter(lambda x: x.lower().startswith(\"afric\"), terms_into_list))[:2] \n",
    "turkey = list(filter(lambda x: x.lower().startswith(\"turk\"), terms_into_list)) \n",
    "america = list(filter(lambda x: x.lower().startswith(\"ameri\"), terms_into_list)) \n",
    "us =list(filter(lambda x: x.lower().startswith(\"usa\"), terms_into_list)) \n",
    "EU = list(filter(lambda x: x.lower().startswith(\"europ\"), terms_into_list))[:2] \n",
    "french.append('franc')\n",
    "group_of_terms = [britian, japan, argentina, australia, brazil, canada, french, germany,\n",
    "    india, indonesian, italy, korea, mexico, Arabia, South_African, america, us, EU]\n",
    "britian_count = 0\n",
    "japan_count = 0\n",
    "argentina_count = 0\n",
    "australia_count = 0 \n",
    "brazil_count = 0\n",
    "canada_count = 0\n",
    "french_count = 0\n",
    "germany_count = 0\n",
    "india_count = 0\n",
    "indonesian_count = 0\n",
    "italy_count = 0\n",
    "korea_count = 0\n",
    "mexico_count = 0\n",
    "Arabia_count = 0\n",
    "South_African_count = 0\n",
    "america_count = 0\n",
    "us_count = 0\n",
    "EU_count = 0\n",
    "\n",
    "Counters_Country = [britian_count,japan_count,argentina_count,australia_count,brazil_count,canada_count,french_count,\n",
    "    germany_count,india_count,indonesian_count,italy_count,korea_count,mexico_count,Arabia_count,South_African_count,america_count,us_count,EU_count]\n",
    "    \n",
    "terms_to_look_for = []\n",
    "for values in group_of_terms:\n",
    "    terms_to_look_for.extend(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['athletics','cricket','football','rugby','tennis']\n",
    "Testing_OutPut = []\n",
    "for values in classes:    \n",
    "    filter_col = [col for col in df if col.startswith(values)]\n",
    "    new_dataframe = df[filter_col]\n",
    "\n",
    "    Results = []\n",
    "    for x in range(len(filter_col)):\n",
    "        test = new_dataframe.iloc[:,x]\n",
    "        test = pd.DataFrame(test)\n",
    "        test['terms'] = terms_into_list\n",
    "        test.columns = ['Values', 'Terms']\n",
    "        test_ordered = test.loc[(test[['Values']] != 0).all(axis=1)]\n",
    "\n",
    "        list_of_top_values = test_ordered['Terms']\n",
    "        output = ' '.join(list_of_top_values)\n",
    "        Results.append(output)\n",
    "\n",
    "    Test = {}\n",
    "    for y in Results:\n",
    "        split = y.split()\n",
    "        for strings in split:\n",
    "            if strings in Test:\n",
    "                for key,value in Test.items():\n",
    "                    if key == strings:\n",
    "                        Test[key] = value + 1\n",
    "\n",
    "\n",
    "            else:\n",
    "                x = 1\n",
    "                Test[strings] = x\n",
    "    Testing_OutPut.append((Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['athletics','cricket','football','rugby','tennis']\n",
    "\n",
    "athletics_dict, athletics_list = getting_topics(Testing_OutPut, 'athletics', classes)\n",
    "cricket_dict, cricket_list = getting_topics(Testing_OutPut, 'cricket', classes)\n",
    "football_dict, football_list = getting_topics(Testing_OutPut, 'football', classes)\n",
    "rugby_dict, rugby_list = getting_topics(Testing_OutPut, 'rugby', classes)\n",
    "tennis_dict, tennis_list = getting_topics(Testing_OutPut, 'tennis', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is looked at each list and look at the top results to get the general topic of said results. \n",
    "\n",
    "###### Example Code of Process is Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('olymp', 72),\n",
       " ('year', 70),\n",
       " ('world', 64),\n",
       " ('athlet', 63),\n",
       " ('champion', 55),\n",
       " ('win', 53),\n",
       " ('race', 50),\n",
       " ('time', 47),\n",
       " ('championship', 46),\n",
       " ('athen', 42),\n",
       " ('european', 41),\n",
       " ('indoor', 41),\n",
       " ('set', 41),\n",
       " ('take', 40),\n",
       " ('final', 40),\n",
       " ('befor', 40),\n",
       " ('sport', 39),\n",
       " ('british', 38),\n",
       " ('month', 38),\n",
       " ('gold', 38),\n",
       " ('compet', 38),\n",
       " ('run', 37),\n",
       " ('great', 37),\n",
       " ('go', 35),\n",
       " ('on', 35),\n",
       " ('record', 34),\n",
       " ('britain', 34),\n",
       " ('second', 33),\n",
       " ('finish', 33),\n",
       " ('best', 33),\n",
       " ('start', 33),\n",
       " ('medal', 32),\n",
       " ('mark', 32),\n",
       " ('intern', 32),\n",
       " ('back', 32),\n",
       " ('first', 31),\n",
       " ('titl', 31),\n",
       " ('train', 31),\n",
       " ('get', 31),\n",
       " ('trial', 31),\n",
       " ('sprinter', 31),\n",
       " ('game', 30),\n",
       " ('season', 29),\n",
       " ('three', 29),\n",
       " ('week', 29),\n",
       " ('two', 29),\n",
       " ('ban', 29),\n",
       " ('test', 29),\n",
       " ('event', 28),\n",
       " ('drug', 28)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athletics_list[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "athletics number of references to countries 78\n",
      "78\n",
      "cricket number of references to countries 101\n",
      "179\n",
      "football number of references to countries 111\n",
      "290\n",
      "rugby number of references to countries 116\n",
      "406\n",
      "tennis number of references to countries 89\n",
      "495\n"
     ]
    }
   ],
   "source": [
    "classes = ['athletics','cricket','football','rugby','tennis']\n",
    "Testing_OutPut = []\n",
    "Total = 0\n",
    "for values in classes:    \n",
    "    filter_col = [col for col in df if col.startswith(values)]\n",
    "    new_dataframe = df[filter_col]\n",
    "\n",
    "    Results = []\n",
    "    for x in range(len(filter_col)):\n",
    "        test = new_dataframe.iloc[:,x]\n",
    "        test = pd.DataFrame(test)\n",
    "        test['terms'] = terms_into_list\n",
    "        test.columns = ['Values', 'Terms']\n",
    "        test_ordered = test.loc[(test[['Values']] != 0).all(axis=1)]\n",
    "\n",
    "        list_of_top_values = test_ordered['Terms']\n",
    "        output = ' '.join(list_of_top_values)\n",
    "        Results.append(output)\n",
    "\n",
    "    Counter = 0 \n",
    "    for y in Results:\n",
    "        split = y.split()\n",
    "        for strings in split:\n",
    "            if strings in terms_to_look_for:\n",
    "                Counter += 1\n",
    "                break\n",
    "            else: \n",
    "                continue\n",
    "    Total += Counter\n",
    "\n",
    "    for y in Results:\n",
    "        split = y.split()\n",
    "        for strings in split:\n",
    "            # for countries in group_of_terms:\n",
    "            testing_value = 0\n",
    "            while testing_value >= (len(Counters_Country) - 1):\n",
    "                if strings in group_of_terms[testing_value]:\n",
    "                    Counters_Country[testing_value] += 1\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "\n",
    "    for y in Results:\n",
    "        split = y.split()\n",
    "        if any(z in max(split, terms_to_look_for, key=len) for z in min(terms_to_look_for, split, key=len)) == True:\n",
    "            testing_value = 0\n",
    "            while testing_value <= (len(Counters_Country) - 1):\n",
    "                if any(t in max(split, group_of_terms[testing_value], key=len) for t in min(group_of_terms[testing_value], split, key=len)) == True:\n",
    "                    Counters_Country[testing_value] += 1\n",
    "                    break\n",
    "                else: \n",
    "                    testing_value +=1 \n",
    "                        \n",
    "    print(values, 'number of references to countries' , Counter)\n",
    "    print(Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "britian count 92\n",
      "japan count 6\n",
      "argentina_count 18\n",
      "australia_count 123\n",
      "brazil_count 18\n",
      "canada_count 4\n",
      "french_count 84\n",
      "germany_count 17\n",
      "india_count 13\n",
      "indonesian_count 0\n",
      "italy_count 24\n",
      "korea_count 0\n",
      "mexico_count 2\n",
      "Arabia_count 0\n",
      "South_African_count 49\n",
      "america_count 13\n",
      "us_count 1\n",
      "EU_count 31\n",
      "total counter 495\n"
     ]
    }
   ],
   "source": [
    "Countries_Counters_Print_Out = ['britian count','japan count','argentina_count',\n",
    "    'australia_count','brazil_count', 'canada_count','french_count','germany_count','india_count', \n",
    "    'indonesian_count', 'italy_count','korea_count','mexico_count','Arabia_count','South_African_count','america_count',\n",
    "    'us_count','EU_count',]\n",
    "\n",
    "totals_test = 0 \n",
    "print_out_counter = 0 \n",
    "for values in Counters_Country:\n",
    "    totals_test += values \n",
    "    print(Countries_Counters_Print_Out[print_out_counter], values)\n",
    "    print_out_counter+=1\n",
    "print('total counter', totals_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Countries Counter   |   Number of Articles |\n",
      "|---:|:--------------------|---------------------:|\n",
      "|  0 | britian count       |                   92 |\n",
      "|  1 | japan count         |                    6 |\n",
      "|  2 | argentina_count     |                   18 |\n",
      "|  3 | australia_count     |                  123 |\n",
      "|  4 | brazil_count        |                   18 |\n",
      "|  5 | canada_count        |                    4 |\n",
      "|  6 | french_count        |                   84 |\n",
      "|  7 | germany_count       |                   17 |\n",
      "|  8 | india_count         |                   13 |\n",
      "|  9 | indonesian_count    |                    0 |\n",
      "| 10 | italy_count         |                   24 |\n",
      "| 11 | korea_count         |                    0 |\n",
      "| 12 | mexico_count        |                    2 |\n",
      "| 13 | Arabia_count        |                    0 |\n",
      "| 14 | South_African_count |                   49 |\n",
      "| 15 | america_count       |                   13 |\n",
      "| 16 | us_count            |                    1 |\n",
      "| 17 | EU_count            |                   31 |\n"
     ]
    }
   ],
   "source": [
    "bbc_table_sports_country = pd.DataFrame([Countries_Counters_Print_Out, Counters_Country]).T\n",
    "bbc_table_sports_country.columns = ['Countries Counter', 'Number of Articles']\n",
    "print(bbc_table_sports_country.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic #1 : Using the BBC dataset \n",
    "\n",
    "##### Question 1: For each of the five categories: what are the most common topics among articles?\n",
    "\n",
    "###### For Businesses the most common topic was current years financial reports. looking at growth reports in specific sectors as well as looking at the return on investments. \n",
    "\n",
    "###### For Entertainment the Most common topics are looking at award shows and who place where in specific music or genres. \n",
    "\n",
    "###### For politics, the main topic is about the governing body specifically looking at the different factions within the political sphere. They also seem to use the BBC as a reference for their debates and topics on politics\n",
    "\n",
    "###### For sports, the main topics are wins vs loses, who has won where and why. As well as identifying areas in which a win could be affected such as injuries or prospects of a new player or replacement. \n",
    "\n",
    "###### For tech, it seems that the major focus of the tech is the interaction between \"People\" and the relationship with the technologies that were produced. As well as looking at the different groups of tech firms. \n",
    "\n",
    "##### Question 2: Across all categories: how many articles talk about each of the G20 countries?\n",
    "\n",
    "###### Across all countries of the G20 there were 1425 which referenced or were referencing the G20, of those countries the specific category spread was, business number of references to countries 356, entertainment number of references to countries 237, politics number of references to countries 262, sport number of references to countries 338, tech number of references to countries 232. As shown on the table below is the specific count of each G20 country coming up in the article. The reason for a higher number than what article is because multiple countries are referenced in a single article. \n",
    "\n",
    "| Countries Counter   |   Number of Articles |\n",
    "|:--------------------|---------------------:|\n",
    "| britian        |                 1582 |\n",
    "| japan          |                  411 |\n",
    "| argentina      |                   93 |\n",
    "| australia      |                  302 |\n",
    "| brazil         |                   87 |\n",
    "| canada         |                   81 |\n",
    "| french         |                  494 |\n",
    "| germany        |                  287 |\n",
    "| india          |                  408 |\n",
    "| indonesian     |                   10 |\n",
    "| italy          |                  136 |\n",
    "| korea          |                   45 |\n",
    "| mexico         |                   24 |\n",
    "| Arabia         |                   30 |\n",
    "| South_African  |                  121 |\n",
    "| america        |                  427 |\n",
    "| us             |                   29 |\n",
    "| EU             |                  420 |\n",
    "\n",
    "\n",
    "#### Question 3: Describe the methodologies you used to solve questions 1 and 2\n",
    "\n",
    "###### The dataset had already be run on using a form of Linear Discriminant Analysis, the next steps would be to actually contextualize the data that was presented to me. The first step was to actually pull out the mtx file and set in in a way that is readable as well as align the corresponding axis to the correct values this being the classification, or the topic (word) designation. After this it was simply being able to subset into the different classes. This was done through splitting the dataframe into sections then re appending the row labels on to this subset. After this was done the next step was to analyze the words, specifically I removed the words on columns which had 0's then summed the count of rows based upon each column of that subset. this gives me the total number of outputs specifically the results of the most used words / topics attributed to the specific category. In tackling the 2nd question, the issue of speed of my process was wrong, it took too long to iteratively go through each word and reference it back to the specific list of G20 specific words. As a result, is used a faster method which is to look at all the words in total against all the words in G20 list, and then filter out the ones that didn't have said words. From there you then match based upon country, which is tallied by a counter. Because of this it goes through each G20 country lists word, which allows for instances of looking at multiple G20 countries in a single article. \n",
    "\n",
    "#### Question 4: What tools did you use for this analysis?\n",
    "\n",
    "###### Because the LDP was already ran and the matrix was already made, I didn't have to use much in the way of Sklearn or even pyspark. Instead, I used mainly python functions, pandas and SciPy to access the mtx file. \n",
    "\n",
    "#### Question 5: How much time did you devote to the exercise? \n",
    "\n",
    "###### In total I spent about 7 hours on this project, most of the time was spent actually understanding the files that I had downloaded. As well as optimize the original way I was planning on doing the project. \n",
    "\n",
    "#### Question 6: If you had more time how would you strengthen your answer for question 2?\n",
    "\n",
    "###### With more time, I think trying to figure out specifics in terms of intent on articles with multiple countries would be good to look at. Because sometimes they may just vaguely reference a country, and not really be the main focus of said article. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic 2: BBC Sports: \n",
    "\n",
    "#### Question 1: For each of the five categories: what are the most common topics among articles?\n",
    "\n",
    "###### For athletics the articles primarily focused on the Olympics as well as placing in the Olympics. On the Olympics specifically looking at racing, indoor sports, and track and field events\n",
    "\n",
    "###### For Cricket, the topics are focusing on the play of the ball such as the wicket, as well as players and positions I assume being captain and how they're fairing in the game. The overall topic is a basic review and play by play of the game at hand as well as short and small discussions on player achievement / success in the game. \n",
    "\n",
    "###### For Football, the topic has to do with specifically world cup action as well as league placements. They also discuss specific teams as well as how they're doing within their league. \n",
    "\n",
    "###### For Rugby, topic is more about the state of the game as well as the teams specifically the ones in different countries such as Ireland, France, and England. As well as reactions or write ups on coaches decisions and plays made during the game. \n",
    "\n",
    "###### For Tennis the main topic is the Opens, and the seeding of placements. The topics are who's playing who and the past and future champions. They talk about the games as well as the order in which it looks to be happening. As well as player success and fitness how they're doing and their injury time. \n",
    "\n",
    "#### Question 2: Across all categories: how many articles talk about each of the G20 countries?\n",
    "\n",
    "###### There seems to have been only 503 out of 737 articles, these are using the same abbreviations and listings as the previous G20 countries. For Category Breakdown based upon the sports is as follows: athletics number of references to countries 78,cricket number of references to countries 101, football number of references to countries 111, rugby number of references to countries 116, tennis number of references to countries 89. But for the specifics in terms of country articles this is the breakdown: \n",
    "| Countries Counter   |   Number of Articles |\n",
    "|:--------------------|---------------------:|\n",
    "| britian        |                   92 |\n",
    "| japan          |                    6 |\n",
    "| argentina      |                   18 |\n",
    "| australia      |                  123 |\n",
    "| brazil        |                   18 |\n",
    "| canada        |                    4 |\n",
    "| french        |                   84 |\n",
    "| germany        |                   17 |\n",
    "| india          |                   13 |\n",
    "| indonesian     |                    0 |\n",
    "| italy          |                   24 |\n",
    "| korea          |                    0 |\n",
    "| mexico         |                    2 |\n",
    "| Arabia         |                    0 |\n",
    "| South_African  |                   49 |\n",
    "| america        |                   13 |\n",
    "| us             |                    1 |\n",
    "| EU             |                   31 |\n",
    "\n",
    "#### Question 3: Describe the methodologies you used to solve questions 1 and 2.\n",
    "\n",
    "###### The dataset had already be run on using a form of Linear Discriminant Analysis, the next steps would be to actually contextualize the data that was presented to me. The first step was to actually pull out the mtx file and set in in a way that is readable as well as align the corresponding axis to the correct values this being the classification, or the topic (word) designation. After this it was simply being able to subset into the different classes. This was done through splitting the dataframe into sections then re appending the row labels on to this subset. After this was done the next step was to analyze the words, specifically I removed the words on columns which had 0's then summed the count of rows based upon each column of that subset. this gives me the total number of outputs specifically the results of the most used words / topics attributed to the specific category. In tackling the 2nd question, the issue of speed of my process was wrong, it took too long to iteratively go through each word and reference it back to the specific list of G20 specific words. As a result, is used a faster method which is to look at all the words in total against all the words in G20 list, and then filter out the ones that didn't have said words. From there you then match based upon country, which is tallied by a counter. Because of this it goes through each G20 country lists word, which allows for instances of looking at multiple G20 countries in a single article. \n",
    "\n",
    "#### Question 4: What tools did you use for this analysis?\n",
    "\n",
    "###### Because the LDP was already ran and the matrix was already made, I didn't have to use much in the way of Sklearn or even pyspark. Instead, I used mainly python functions, pandas and SciPy to access the mtx file. \n",
    "\n",
    "#### Question 5: How much time did you devote to the exercise? \n",
    "\n",
    "###### This project took only an hour because I followed the same coding process as I did for the BBC_Data.\n",
    "\n",
    "#### Question 6: If you had more time how would you strengthen your answer for question 2?\n",
    "\n",
    "###### I believe that this project would be beneficial to look at the relationships between countries competing, specifically try to nail down the articles that are about matches. This is because it could prevent future issues with double counters for countries because it references both teams. Another would be to work on the EU words, since Europo is a term used to ID articles, this could be prevent mislabeling with Europo Cup or some version of a Cup title. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1600b08eb054f89f1d3fd7d41e80cbb6cb92b16b32be617c82557d838b2f27c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('Data Science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
